{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "liberal-journalist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-143.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>71.5</td>\n",
       "      <td>75.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start   end  salience  fold  classID  \\\n",
       "0  100263-2-0-117.wav  100263   58.5  62.5         1     5        2   \n",
       "1  100263-2-0-121.wav  100263   60.5  64.5         1     5        2   \n",
       "2  100263-2-0-126.wav  100263   63.0  67.0         1     5        2   \n",
       "3  100263-2-0-137.wav  100263   68.5  72.5         1     5        2   \n",
       "4  100263-2-0-143.wav  100263   71.5  75.5         1     5        2   \n",
       "\n",
       "              class  \n",
       "0  children_playing  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "audio_dataset_path='UrbanSound8K/'\n",
    "metadata=pd.read_csv('UrbanSound8K/UrbanSound8K.csv')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chinese-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nuclear-sponsorship",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3553it [07:07,  9.20it/s]D:\\Jupyter\\envs\\tensorflow\\lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "8322it [14:54, 26.21it/s]D:\\Jupyter\\envs\\tensorflow\\lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "8326it [14:55, 29.55it/s]D:\\Jupyter\\envs\\tensorflow\\lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
      "  warnings.warn(\n",
      "8731it [15:14,  9.55it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "extracted_features=[]\n",
    "c=1\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"])).replace(\"\\\\\",\"/\")\n",
    "    final_class_labels=row[\"class\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acoustic-wagner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-424.09818, 109.34077, -52.919525, 60.86475, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-458.79114, 121.38419, -46.520657, 52.00812, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-413.89984, 101.66371, -35.42945, 53.036354, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-446.60352, 113.68541, -52.402218, 60.302044,...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-446.8255, 117.011925, -33.7923, 55.406204, 2...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature             class\n",
       "0  [-424.09818, 109.34077, -52.919525, 60.86475, ...  children_playing\n",
       "1  [-458.79114, 121.38419, -46.520657, 52.00812, ...  children_playing\n",
       "2  [-413.89984, 101.66371, -35.42945, 53.036354, ...  children_playing\n",
       "3  [-446.60352, 113.68541, -52.402218, 60.302044,...  children_playing\n",
       "4  [-446.8255, 117.011925, -33.7923, 55.406204, 2...  children_playing"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### converting extracted_features to Pandas dataframe\n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "characteristic-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "friendly-placement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8731, 40)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "japanese-cheese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['children_playing', 'children_playing', 'children_playing', ...,\n",
       "       'car_horn', 'car_horn', 'car_horn'], dtype='<U16')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wired-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sitting-anniversary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "documentary-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "analyzed-payday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.12337402e+02,  6.10992813e+01, -3.18407097e+01, ...,\n",
       "        -1.65826523e+00, -1.99171209e+00,  2.66584349e+00],\n",
       "       [-2.51385864e+02,  1.33342346e+02, -1.06559610e+01, ...,\n",
       "        -2.38794994e+00, -4.75240517e+00, -5.88469839e+00],\n",
       "       [-2.51105194e+02,  1.24307274e+02,  7.52227736e+00, ...,\n",
       "        -4.09622416e-02,  9.93638337e-02,  5.03649950e-01],\n",
       "       ...,\n",
       "       [-5.10315063e+02,  8.80034409e+01, -5.02600241e+00, ...,\n",
       "         2.61844218e-01, -3.40468377e-01, -1.64568985e+00],\n",
       "       [-1.49709091e+02,  1.38775314e+02, -3.20417595e+01, ...,\n",
       "         4.44790363e-01, -1.55924821e+00, -1.42068398e+00],\n",
       "       [-4.25987091e+02,  2.08752579e+02,  1.58930099e+00, ...,\n",
       "        -3.81701732e+00, -1.41003668e+00, -3.94950747e-01]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "female-study",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "flexible-lithuania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6984, 40)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "instrumental-equity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1747, 40)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "chemical-vermont",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6984, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "governing-natural",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1747, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-vessel",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "loose-portugal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "indonesian-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "valuable-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "### No of classes\n",
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "found-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "described-anaheim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,410\n",
      "Trainable params: 45,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "radical-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "alpha-adapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9120 - accuracy: 0.6984\n",
      "Epoch 1: val_loss improved from inf to 0.72797, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9114 - accuracy: 0.6987 - val_loss: 0.7280 - val_accuracy: 0.7733\n",
      "Epoch 2/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.9525 - accuracy: 0.6942\n",
      "Epoch 2: val_loss did not improve from 0.72797\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9516 - accuracy: 0.6943 - val_loss: 0.7669 - val_accuracy: 0.7584\n",
      "Epoch 3/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.9439 - accuracy: 0.6848\n",
      "Epoch 3: val_loss did not improve from 0.72797\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9429 - accuracy: 0.6850 - val_loss: 0.7485 - val_accuracy: 0.7630\n",
      "Epoch 4/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.9354 - accuracy: 0.6907\n",
      "Epoch 4: val_loss did not improve from 0.72797\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9331 - accuracy: 0.6914 - val_loss: 0.7592 - val_accuracy: 0.7653\n",
      "Epoch 5/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.9487 - accuracy: 0.6878\n",
      "Epoch 5: val_loss did not improve from 0.72797\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9495 - accuracy: 0.6880 - val_loss: 0.7621 - val_accuracy: 0.7624\n",
      "Epoch 6/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.9644 - accuracy: 0.6866\n",
      "Epoch 6: val_loss did not improve from 0.72797\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9636 - accuracy: 0.6867 - val_loss: 0.7594 - val_accuracy: 0.7624\n",
      "Epoch 7/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.9388 - accuracy: 0.6941\n",
      "Epoch 7: val_loss did not improve from 0.72797\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9346 - accuracy: 0.6956 - val_loss: 0.7604 - val_accuracy: 0.7636\n",
      "Epoch 8/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 0.9410 - accuracy: 0.6894\n",
      "Epoch 8: val_loss did not improve from 0.72797\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9425 - accuracy: 0.6893 - val_loss: 0.7702 - val_accuracy: 0.7745\n",
      "Epoch 9/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9386 - accuracy: 0.6889\n",
      "Epoch 9: val_loss did not improve from 0.72797\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9362 - accuracy: 0.6897 - val_loss: 0.7536 - val_accuracy: 0.7676\n",
      "Epoch 10/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9565 - accuracy: 0.6836\n",
      "Epoch 10: val_loss did not improve from 0.72797\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9606 - accuracy: 0.6820 - val_loss: 0.7370 - val_accuracy: 0.7762\n",
      "Epoch 11/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 0.9319 - accuracy: 0.7005\n",
      "Epoch 11: val_loss did not improve from 0.72797\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9359 - accuracy: 0.6999 - val_loss: 0.7815 - val_accuracy: 0.7630\n",
      "Epoch 12/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9282 - accuracy: 0.6944\n",
      "Epoch 12: val_loss did not improve from 0.72797\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9276 - accuracy: 0.6939 - val_loss: 0.7457 - val_accuracy: 0.7682\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9355 - accuracy: 0.6861\n",
      "Epoch 13: val_loss did not improve from 0.72797\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9355 - accuracy: 0.6861 - val_loss: 0.7659 - val_accuracy: 0.7687\n",
      "Epoch 14/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9343 - accuracy: 0.6919\n",
      "Epoch 14: val_loss did not improve from 0.72797\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9344 - accuracy: 0.6936 - val_loss: 0.7808 - val_accuracy: 0.7636\n",
      "Epoch 15/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.9403 - accuracy: 0.6865\n",
      "Epoch 15: val_loss improved from 0.72797 to 0.71714, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9379 - accuracy: 0.6870 - val_loss: 0.7171 - val_accuracy: 0.7773\n",
      "Epoch 16/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.9322 - accuracy: 0.6916\n",
      "Epoch 16: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9315 - accuracy: 0.6920 - val_loss: 0.7399 - val_accuracy: 0.7722\n",
      "Epoch 17/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.9202 - accuracy: 0.6918\n",
      "Epoch 17: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9276 - accuracy: 0.6906 - val_loss: 0.7313 - val_accuracy: 0.7728\n",
      "Epoch 18/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.9097 - accuracy: 0.7031\n",
      "Epoch 18: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9129 - accuracy: 0.7019 - val_loss: 0.7540 - val_accuracy: 0.7670\n",
      "Epoch 19/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9527 - accuracy: 0.6922\n",
      "Epoch 19: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9520 - accuracy: 0.6923 - val_loss: 0.7318 - val_accuracy: 0.7647\n",
      "Epoch 20/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9378 - accuracy: 0.6902\n",
      "Epoch 20: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9377 - accuracy: 0.6909 - val_loss: 0.7429 - val_accuracy: 0.7607\n",
      "Epoch 21/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.9221 - accuracy: 0.6959\n",
      "Epoch 21: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9209 - accuracy: 0.6976 - val_loss: 0.7376 - val_accuracy: 0.7676\n",
      "Epoch 22/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9190 - accuracy: 0.6953\n",
      "Epoch 22: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9175 - accuracy: 0.6962 - val_loss: 0.7279 - val_accuracy: 0.7813\n",
      "Epoch 23/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9038 - accuracy: 0.7004\n",
      "Epoch 23: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9060 - accuracy: 0.7002 - val_loss: 0.7326 - val_accuracy: 0.7768\n",
      "Epoch 24/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.9157 - accuracy: 0.7073\n",
      "Epoch 24: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9143 - accuracy: 0.7075 - val_loss: 0.7340 - val_accuracy: 0.7710\n",
      "Epoch 25/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.9143 - accuracy: 0.6987\n",
      "Epoch 25: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9215 - accuracy: 0.6976 - val_loss: 0.7293 - val_accuracy: 0.7825\n",
      "Epoch 26/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.9145 - accuracy: 0.6961\n",
      "Epoch 26: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9197 - accuracy: 0.6944 - val_loss: 0.7514 - val_accuracy: 0.7773\n",
      "Epoch 27/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.9462 - accuracy: 0.6933\n",
      "Epoch 27: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9456 - accuracy: 0.6926 - val_loss: 0.7236 - val_accuracy: 0.7756\n",
      "Epoch 28/100\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 0.9245 - accuracy: 0.7028\n",
      "Epoch 28: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9252 - accuracy: 0.7005 - val_loss: 0.7294 - val_accuracy: 0.7728\n",
      "Epoch 29/100\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.9379 - accuracy: 0.6984\n",
      "Epoch 29: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9324 - accuracy: 0.7007 - val_loss: 0.7341 - val_accuracy: 0.7773\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/219 [==========================>...] - ETA: 0s - loss: 0.9186 - accuracy: 0.7021\n",
      "Epoch 30: val_loss did not improve from 0.71714\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9138 - accuracy: 0.7030 - val_loss: 0.7205 - val_accuracy: 0.7722\n",
      "Epoch 31/100\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 0.9037 - accuracy: 0.6950\n",
      "Epoch 31: val_loss improved from 0.71714 to 0.70590, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9058 - accuracy: 0.6940 - val_loss: 0.7059 - val_accuracy: 0.7876\n",
      "Epoch 32/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9298 - accuracy: 0.7010\n",
      "Epoch 32: val_loss did not improve from 0.70590\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9297 - accuracy: 0.7010 - val_loss: 0.7338 - val_accuracy: 0.7762\n",
      "Epoch 33/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.8987 - accuracy: 0.7061\n",
      "Epoch 33: val_loss did not improve from 0.70590\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9019 - accuracy: 0.7052 - val_loss: 0.7148 - val_accuracy: 0.7836\n",
      "Epoch 34/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9105 - accuracy: 0.7084\n",
      "Epoch 34: val_loss did not improve from 0.70590\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9121 - accuracy: 0.7069 - val_loss: 0.7360 - val_accuracy: 0.7716\n",
      "Epoch 35/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.9108 - accuracy: 0.7022\n",
      "Epoch 35: val_loss did not improve from 0.70590\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9094 - accuracy: 0.7026 - val_loss: 0.7095 - val_accuracy: 0.7733\n",
      "Epoch 36/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9291 - accuracy: 0.6940\n",
      "Epoch 36: val_loss did not improve from 0.70590\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9312 - accuracy: 0.6963 - val_loss: 0.7301 - val_accuracy: 0.7796\n",
      "Epoch 37/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.9096 - accuracy: 0.6990\n",
      "Epoch 37: val_loss did not improve from 0.70590\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9118 - accuracy: 0.6976 - val_loss: 0.7288 - val_accuracy: 0.7728\n",
      "Epoch 38/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.9039 - accuracy: 0.7054\n",
      "Epoch 38: val_loss improved from 0.70590 to 0.68991, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8987 - accuracy: 0.7066 - val_loss: 0.6899 - val_accuracy: 0.7831\n",
      "Epoch 39/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.9174 - accuracy: 0.7025\n",
      "Epoch 39: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9193 - accuracy: 0.7012 - val_loss: 0.7006 - val_accuracy: 0.7871\n",
      "Epoch 40/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8870 - accuracy: 0.7080\n",
      "Epoch 40: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8888 - accuracy: 0.7079 - val_loss: 0.6965 - val_accuracy: 0.7813\n",
      "Epoch 41/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9133 - accuracy: 0.6985\n",
      "Epoch 41: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9106 - accuracy: 0.6990 - val_loss: 0.7126 - val_accuracy: 0.7756\n",
      "Epoch 42/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8987 - accuracy: 0.7073\n",
      "Epoch 42: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8993 - accuracy: 0.7069 - val_loss: 0.7114 - val_accuracy: 0.7825\n",
      "Epoch 43/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.9157 - accuracy: 0.7041\n",
      "Epoch 43: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9125 - accuracy: 0.7046 - val_loss: 0.7186 - val_accuracy: 0.7756\n",
      "Epoch 44/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.8999 - accuracy: 0.7081\n",
      "Epoch 44: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8983 - accuracy: 0.7086 - val_loss: 0.7046 - val_accuracy: 0.7768\n",
      "Epoch 45/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.9027 - accuracy: 0.7074\n",
      "Epoch 45: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9012 - accuracy: 0.7079 - val_loss: 0.7477 - val_accuracy: 0.7710\n",
      "Epoch 46/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.8965 - accuracy: 0.7053\n",
      "Epoch 46: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8989 - accuracy: 0.7043 - val_loss: 0.7454 - val_accuracy: 0.7630\n",
      "Epoch 47/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.9036 - accuracy: 0.7028\n",
      "Epoch 47: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9048 - accuracy: 0.7019 - val_loss: 0.7477 - val_accuracy: 0.7739\n",
      "Epoch 48/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.8975 - accuracy: 0.7042\n",
      "Epoch 48: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8978 - accuracy: 0.7043 - val_loss: 0.7510 - val_accuracy: 0.7676\n",
      "Epoch 49/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.8844 - accuracy: 0.7166\n",
      "Epoch 49: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8805 - accuracy: 0.7175 - val_loss: 0.7054 - val_accuracy: 0.7825\n",
      "Epoch 50/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.9105 - accuracy: 0.7041\n",
      "Epoch 50: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9124 - accuracy: 0.7029 - val_loss: 0.7164 - val_accuracy: 0.7831\n",
      "Epoch 51/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.9053 - accuracy: 0.7096\n",
      "Epoch 51: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9023 - accuracy: 0.7102 - val_loss: 0.7291 - val_accuracy: 0.7710\n",
      "Epoch 52/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.8894 - accuracy: 0.7079\n",
      "Epoch 52: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8914 - accuracy: 0.7072 - val_loss: 0.7173 - val_accuracy: 0.7785\n",
      "Epoch 53/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.9101 - accuracy: 0.6985\n",
      "Epoch 53: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9088 - accuracy: 0.6980 - val_loss: 0.7325 - val_accuracy: 0.7819\n",
      "Epoch 54/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.9123 - accuracy: 0.7002\n",
      "Epoch 54: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9092 - accuracy: 0.7013 - val_loss: 0.7256 - val_accuracy: 0.7790\n",
      "Epoch 55/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.9049 - accuracy: 0.7047\n",
      "Epoch 55: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9088 - accuracy: 0.7029 - val_loss: 0.7447 - val_accuracy: 0.7773\n",
      "Epoch 56/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.8959 - accuracy: 0.7049\n",
      "Epoch 56: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8990 - accuracy: 0.7030 - val_loss: 0.7135 - val_accuracy: 0.7876\n",
      "Epoch 57/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.8725 - accuracy: 0.7129\n",
      "Epoch 57: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8751 - accuracy: 0.7113 - val_loss: 0.7333 - val_accuracy: 0.7825\n",
      "Epoch 58/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9017 - accuracy: 0.7088\n",
      "Epoch 58: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9020 - accuracy: 0.7088 - val_loss: 0.7076 - val_accuracy: 0.7825\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/219 [============================>.] - ETA: 0s - loss: 0.8945 - accuracy: 0.7055\n",
      "Epoch 59: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8948 - accuracy: 0.7058 - val_loss: 0.7189 - val_accuracy: 0.7773\n",
      "Epoch 60/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8953 - accuracy: 0.7050\n",
      "Epoch 60: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8979 - accuracy: 0.7045 - val_loss: 0.7325 - val_accuracy: 0.7722\n",
      "Epoch 61/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8902 - accuracy: 0.7127\n",
      "Epoch 61: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8891 - accuracy: 0.7128 - val_loss: 0.7231 - val_accuracy: 0.7745\n",
      "Epoch 62/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.8940 - accuracy: 0.7035\n",
      "Epoch 62: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8858 - accuracy: 0.7058 - val_loss: 0.6974 - val_accuracy: 0.7876\n",
      "Epoch 63/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.8463 - accuracy: 0.7205\n",
      "Epoch 63: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8468 - accuracy: 0.7204 - val_loss: 0.7422 - val_accuracy: 0.7562\n",
      "Epoch 64/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.8835 - accuracy: 0.7067\n",
      "Epoch 64: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8823 - accuracy: 0.7075 - val_loss: 0.7103 - val_accuracy: 0.7831\n",
      "Epoch 65/100\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.8955 - accuracy: 0.7112\n",
      "Epoch 65: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8949 - accuracy: 0.7118 - val_loss: 0.6989 - val_accuracy: 0.7876\n",
      "Epoch 66/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.8888 - accuracy: 0.7109\n",
      "Epoch 66: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8879 - accuracy: 0.7095 - val_loss: 0.7224 - val_accuracy: 0.7705\n",
      "Epoch 67/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.8800 - accuracy: 0.7112\n",
      "Epoch 67: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8765 - accuracy: 0.7119 - val_loss: 0.7036 - val_accuracy: 0.7768\n",
      "Epoch 68/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.8929 - accuracy: 0.7021\n",
      "Epoch 68: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8874 - accuracy: 0.7039 - val_loss: 0.7218 - val_accuracy: 0.7722\n",
      "Epoch 69/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9056 - accuracy: 0.7043\n",
      "Epoch 69: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9052 - accuracy: 0.7043 - val_loss: 0.7280 - val_accuracy: 0.7705\n",
      "Epoch 70/100\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.8965 - accuracy: 0.7052\n",
      "Epoch 70: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8954 - accuracy: 0.7058 - val_loss: 0.7220 - val_accuracy: 0.7779\n",
      "Epoch 71/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.8741 - accuracy: 0.7171\n",
      "Epoch 71: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8794 - accuracy: 0.7161 - val_loss: 0.7059 - val_accuracy: 0.7922\n",
      "Epoch 72/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.9025 - accuracy: 0.7022\n",
      "Epoch 72: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9004 - accuracy: 0.7033 - val_loss: 0.7062 - val_accuracy: 0.7848\n",
      "Epoch 73/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.8792 - accuracy: 0.7138\n",
      "Epoch 73: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8799 - accuracy: 0.7133 - val_loss: 0.7002 - val_accuracy: 0.7848\n",
      "Epoch 74/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.8706 - accuracy: 0.7103\n",
      "Epoch 74: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8700 - accuracy: 0.7102 - val_loss: 0.7185 - val_accuracy: 0.7728\n",
      "Epoch 75/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.8816 - accuracy: 0.7111\n",
      "Epoch 75: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8800 - accuracy: 0.7111 - val_loss: 0.7665 - val_accuracy: 0.7659\n",
      "Epoch 76/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.8872 - accuracy: 0.7059\n",
      "Epoch 76: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8880 - accuracy: 0.7058 - val_loss: 0.7107 - val_accuracy: 0.7876\n",
      "Epoch 77/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.8841 - accuracy: 0.7125\n",
      "Epoch 77: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8833 - accuracy: 0.7129 - val_loss: 0.7066 - val_accuracy: 0.7945\n",
      "Epoch 78/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8738 - accuracy: 0.7115\n",
      "Epoch 78: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8747 - accuracy: 0.7116 - val_loss: 0.6985 - val_accuracy: 0.7853\n",
      "Epoch 79/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.8776 - accuracy: 0.7124\n",
      "Epoch 79: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8807 - accuracy: 0.7126 - val_loss: 0.7081 - val_accuracy: 0.7808\n",
      "Epoch 80/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.8682 - accuracy: 0.7139\n",
      "Epoch 80: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8636 - accuracy: 0.7174 - val_loss: 0.6955 - val_accuracy: 0.7865\n",
      "Epoch 81/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.8597 - accuracy: 0.7147\n",
      "Epoch 81: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8611 - accuracy: 0.7141 - val_loss: 0.7445 - val_accuracy: 0.7779\n",
      "Epoch 82/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.8977 - accuracy: 0.7060\n",
      "Epoch 82: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8960 - accuracy: 0.7060 - val_loss: 0.6954 - val_accuracy: 0.7894\n",
      "Epoch 83/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.8611 - accuracy: 0.7217\n",
      "Epoch 83: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8591 - accuracy: 0.7224 - val_loss: 0.7083 - val_accuracy: 0.7911\n",
      "Epoch 84/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.8616 - accuracy: 0.7124\n",
      "Epoch 84: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8635 - accuracy: 0.7113 - val_loss: 0.7275 - val_accuracy: 0.7785\n",
      "Epoch 85/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.8860 - accuracy: 0.7063\n",
      "Epoch 85: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8872 - accuracy: 0.7060 - val_loss: 0.7430 - val_accuracy: 0.7716\n",
      "Epoch 86/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.8629 - accuracy: 0.7150\n",
      "Epoch 86: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8580 - accuracy: 0.7161 - val_loss: 0.7023 - val_accuracy: 0.7842\n",
      "Epoch 87/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.9044 - accuracy: 0.7081\n",
      "Epoch 87: val_loss did not improve from 0.68991\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8993 - accuracy: 0.7090 - val_loss: 0.6946 - val_accuracy: 0.7859\n",
      "Epoch 88/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.8648 - accuracy: 0.7177\n",
      "Epoch 88: val_loss improved from 0.68991 to 0.68621, saving model to saved_models\\audio_classification.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8643 - accuracy: 0.7164 - val_loss: 0.6862 - val_accuracy: 0.7848\n",
      "Epoch 89/100\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 0.8749 - accuracy: 0.7081\n",
      "Epoch 89: val_loss did not improve from 0.68621\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8749 - accuracy: 0.7080 - val_loss: 0.7122 - val_accuracy: 0.7790\n",
      "Epoch 90/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.8836 - accuracy: 0.7088\n",
      "Epoch 90: val_loss did not improve from 0.68621\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8885 - accuracy: 0.7079 - val_loss: 0.7128 - val_accuracy: 0.7813\n",
      "Epoch 91/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8776 - accuracy: 0.7059\n",
      "Epoch 91: val_loss did not improve from 0.68621\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8750 - accuracy: 0.7068 - val_loss: 0.7009 - val_accuracy: 0.7831\n",
      "Epoch 92/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.8739 - accuracy: 0.7129\n",
      "Epoch 92: val_loss did not improve from 0.68621\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8724 - accuracy: 0.7126 - val_loss: 0.7061 - val_accuracy: 0.7756\n",
      "Epoch 93/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.8516 - accuracy: 0.7186\n",
      "Epoch 93: val_loss did not improve from 0.68621\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8521 - accuracy: 0.7186 - val_loss: 0.7182 - val_accuracy: 0.7853\n",
      "Epoch 94/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.8647 - accuracy: 0.7102\n",
      "Epoch 94: val_loss did not improve from 0.68621\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8632 - accuracy: 0.7109 - val_loss: 0.7144 - val_accuracy: 0.7842\n",
      "Epoch 95/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.8631 - accuracy: 0.7143\n",
      "Epoch 95: val_loss did not improve from 0.68621\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8659 - accuracy: 0.7139 - val_loss: 0.7093 - val_accuracy: 0.7802\n",
      "Epoch 96/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.8474 - accuracy: 0.7190\n",
      "Epoch 96: val_loss did not improve from 0.68621\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8452 - accuracy: 0.7198 - val_loss: 0.6930 - val_accuracy: 0.7882\n",
      "Epoch 97/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.8681 - accuracy: 0.7115\n",
      "Epoch 97: val_loss did not improve from 0.68621\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8670 - accuracy: 0.7128 - val_loss: 0.7034 - val_accuracy: 0.7831\n",
      "Epoch 98/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.8743 - accuracy: 0.7038\n",
      "Epoch 98: val_loss did not improve from 0.68621\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8734 - accuracy: 0.7038 - val_loss: 0.7056 - val_accuracy: 0.7934\n",
      "Epoch 99/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.8775 - accuracy: 0.7126\n",
      "Epoch 99: val_loss did not improve from 0.68621\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8736 - accuracy: 0.7151 - val_loss: 0.7019 - val_accuracy: 0.7911\n",
      "Epoch 100/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.8577 - accuracy: 0.7142\n",
      "Epoch 100: val_loss improved from 0.68621 to 0.68066, saving model to saved_models\\audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8602 - accuracy: 0.7143 - val_loss: 0.6807 - val_accuracy: 0.7956\n",
      "Training completed in time:  0:01:28.128403\n"
     ]
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "virgin-butter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7956497073173523\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "strange-driving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-102.88505   ,   87.88047   ,  -28.99793   ,   16.018013  ,\n",
       "          1.2033683 ,   16.61361   ,  -13.97893   ,   17.469175  ,\n",
       "         -5.9888306 ,   14.429839  ,  -17.82136   ,    3.3612053 ,\n",
       "        -11.023228  ,   14.444955  ,    5.394709  ,   30.56515   ,\n",
       "          5.5551596 ,   13.035866  ,   -6.269046  ,    7.8246922 ,\n",
       "         -9.91783   ,   11.382298  ,  -12.103567  ,    2.8155384 ,\n",
       "         -2.8936207 ,    6.367891  ,  -11.633807  ,    7.238143  ,\n",
       "         12.592639  ,    6.793665  ,  -14.943717  ,    0.10874656,\n",
       "         13.804669  ,   17.925476  ,   -6.5646725 ,    3.7349968 ,\n",
       "          4.7114425 ,  -18.016933  ,  -19.927252  ,   13.628061  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "intensive-conservative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 1, 7, ..., 9, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-booth",
   "metadata": {},
   "source": [
    "### Testing Some Test Audio Data\n",
    "\n",
    "Steps\n",
    "- Preprocess the new audio data\n",
    "- predict the classes\n",
    "- Invere transform your Predicted Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "chubby-newsletter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.5683524e+02  8.4114578e+01 -2.2832775e+01 -1.0309464e+01\n",
      "  2.7360733e+00  1.0459924e+00 -6.2581086e+00  1.2818811e+01\n",
      " -3.5566330e+00  8.3815515e-01  3.2011795e+00  9.9730711e+00\n",
      "  2.1779177e+00 -4.0221424e+00 -4.9099975e+00  5.7891160e-01\n",
      "  1.1456020e-01  7.6958501e-01 -4.9822502e+00 -1.6147598e+00\n",
      " -1.9361399e+00 -1.4523536e+00  1.7747289e+00  4.2438450e+00\n",
      " -3.8731721e-01 -1.8724498e+00 -3.8537102e+00 -2.2411184e+00\n",
      " -2.0041037e+00 -1.3309578e+00 -4.9806366e+00 -3.5181143e+00\n",
      " -2.3907588e+00 -1.8754460e+00 -3.2984786e+00 -1.0587918e+00\n",
      " -1.5697086e+00 -2.7484596e+00 -2.2563803e+00 -2.8791909e+00]\n",
      "[[-3.5683524e+02  8.4114578e+01 -2.2832775e+01 -1.0309464e+01\n",
      "   2.7360733e+00  1.0459924e+00 -6.2581086e+00  1.2818811e+01\n",
      "  -3.5566330e+00  8.3815515e-01  3.2011795e+00  9.9730711e+00\n",
      "   2.1779177e+00 -4.0221424e+00 -4.9099975e+00  5.7891160e-01\n",
      "   1.1456020e-01  7.6958501e-01 -4.9822502e+00 -1.6147598e+00\n",
      "  -1.9361399e+00 -1.4523536e+00  1.7747289e+00  4.2438450e+00\n",
      "  -3.8731721e-01 -1.8724498e+00 -3.8537102e+00 -2.2411184e+00\n",
      "  -2.0041037e+00 -1.3309578e+00 -4.9806366e+00 -3.5181143e+00\n",
      "  -2.3907588e+00 -1.8754460e+00 -3.2984786e+00 -1.0587918e+00\n",
      "  -1.5697086e+00 -2.7484596e+00 -2.2563803e+00 -2.8791909e+00]]\n",
      "(1, 40)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['dog_bark'], dtype='<U16')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=\"UrbanSound8K/dog_bark2.wav\"\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "print(mfccs_scaled_features)\n",
    "print(mfccs_scaled_features.shape)\n",
    "predicted_label=model.predict(mfccs_scaled_features)\n",
    "predicted_label=np.argmax(predicted_label,axis=1)\n",
    "predicted_label = np.array(predicted_label)\n",
    "predicted_label = predicted_label.flatten()\n",
    "print(predicted_label)\n",
    "prediction_class = labelencoder.inverse_transform(predicted_label) \n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-theorem",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
